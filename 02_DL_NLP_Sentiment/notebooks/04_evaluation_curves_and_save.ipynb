{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# J3 — Évaluation (chargement modèle J2)\n",
        "\n",
        "Objectifs :\n",
        "- charger le modèle entraîné (J2) : `models/sentiment_model.keras`\n",
        "- charger le vectorizer : `models/text_vectorizer.keras`\n",
        "- évaluer sur **test**\n",
        "- sauvegarder des figures d’évaluation (ROC curve) dans `results/`\n",
        "- sauvegarder les métriques dans `results/metrics.json`\n",
        "\n",
        "Note : `models/` et `*.keras` sont ignorés par git."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project dir: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\n",
            "TensorFlow: 2.13.0\n",
            "Model path: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\\models\\sentiment_model.keras\n",
            "Vectorizer path: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\\models\\text_vectorizer.keras\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "cwd = Path.cwd().resolve()\n",
        "PROJECT_DIR = None\n",
        "for p in [cwd] + list(cwd.parents):\n",
        "    if (p / \"src\").exists():\n",
        "        PROJECT_DIR = p\n",
        "        break\n",
        "if PROJECT_DIR is None:\n",
        "    raise RuntimeError(f\"Could not find project root containing 'src' starting from: {cwd}\")\n",
        "\n",
        "# Make `src.*` imports work\n",
        "sys.path.insert(0, str(PROJECT_DIR))\n",
        "\n",
        "MODELS_DIR = PROJECT_DIR / \"models\"\n",
        "RESULTS_DIR = PROJECT_DIR / \"results\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = MODELS_DIR / \"sentiment_model.keras\"\n",
        "VECTORIZER_PATH = MODELS_DIR / \"text_vectorizer.keras\"\n",
        "\n",
        "print(\"Project dir:\", PROJECT_DIR)\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Model path:\", MODEL_PATH)\n",
        "print(\"Vectorizer path:\", VECTORIZER_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Charger les artefacts (modèle + vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 128)          1280000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 200, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1378945 (5.26 MB)\n",
            "Trainable params: 1378945 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "if not MODEL_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
        "if not VECTORIZER_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Vectorizer not found: {VECTORIZER_PATH}\")\n",
        "\n",
        "# Important: the vectorizer was saved with a custom standardize function.\n",
        "# Provide it explicitly so loading works even if the artifact was created before registration.\n",
        "from src.text_preprocessing import TextPreprocessor\n",
        "\n",
        "model = tf.keras.models.load_model(str(MODEL_PATH))\n",
        "vectorizer_model = tf.keras.models.load_model(\n",
        "    str(VECTORIZER_PATH),\n",
        "    custom_objects={\"_custom_standardize\": TextPreprocessor._custom_standardize},\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Charger IMDB (test, texte brut) + vectoriser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X batch: (256, 200) <dtype: 'int64'>\n",
            "y batch: (256,) <dtype: 'int64'>\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow Datasets: imdb_reviews returns (text, label)\n",
        "test_ds = tfds.load(\"imdb_reviews\", split=\"test\", as_supervised=True)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def vectorize_batch(x, y):\n",
        "    x_vec = vectorizer_model(x)\n",
        "    return x_vec, y\n",
        "\n",
        "test_vec_ds = test_ds.batch(BATCH_SIZE).map(vectorize_batch).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Quick shape check\n",
        "for xb, yb in test_vec_ds.take(1):\n",
        "    print(\"X batch:\", xb.shape, xb.dtype)\n",
        "    print(\"y batch:\", yb.shape, yb.dtype)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Évaluer sur test + ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 21s 198ms/step - loss: 0.3854 - accuracy: 0.8352 - roc_auc: 0.9229\n",
            "{'loss': 0.38541507720947266, 'accuracy': 0.8351600170135498, 'roc_auc': 0.9228788614273071}\n",
            "Saved ROC curve to: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\\results\\roc_curve.png\n"
          ]
        }
      ],
      "source": [
        "# Evaluate using the dataset pipeline\n",
        "metrics = model.evaluate(test_vec_ds, verbose=1)\n",
        "metrics_dict = {name: float(val) for name, val in zip(model.metrics_names, metrics)}\n",
        "print(metrics_dict)\n",
        "\n",
        "# Build ROC curve\n",
        "y_true_all = []\n",
        "y_prob_all = []\n",
        "for xb, yb in test_vec_ds:\n",
        "    probs = model.predict(xb, verbose=0).reshape(-1)\n",
        "    y_true_all.append(yb.numpy().astype(np.int32))\n",
        "    y_prob_all.append(probs.astype(np.float32))\n",
        "\n",
        "y_true = np.concatenate(y_true_all)\n",
        "y_prob = np.concatenate(y_prob_all)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve (IMDB test)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "\n",
        "roc_path = RESULTS_DIR / \"roc_curve.png\"\n",
        "plt.savefig(roc_path, dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved ROC curve to:\", roc_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Sauvegarder les métriques dans results/metrics.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\\results\\metrics.json\n"
          ]
        }
      ],
      "source": [
        "out_json = RESULTS_DIR / \"metrics.json\"\n",
        "payload = {\n",
        "    \"model\": \"BiLSTM\",\n",
        "    \"test_metrics\": metrics_dict,\n",
        "    \"test_roc_auc_sklearn\": float(roc_auc),\n",
        "    \"artifacts\": {\n",
        "        \"model\": str(MODEL_PATH),\n",
        "        \"vectorizer\": str(VECTORIZER_PATH),\n",
        "        \"roc_curve\": str(roc_path),\n",
        "    },\n",
        "}\n",
        "out_json.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved:\", out_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ Fin de J3 :\n",
        "- `results/metrics.json`\n",
        "- `results/roc_curve.png`\n",
        "- modèle + vectorizer chargés depuis `models/` (J2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
