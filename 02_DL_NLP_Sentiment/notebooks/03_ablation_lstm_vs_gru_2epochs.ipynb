{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mini-exercice (obligatoire) — Ablation LSTM vs GRU (2 epochs)\n",
        "\n",
        "Objectif : comparer **LSTM vs GRU** à architecture comparable, sur **2 epochs** uniquement (juste pour observer l'effet).\n",
        "\n",
        "On garde :\n",
        "- même vocabulaire (`MAX_WORDS`)\n",
        "- même longueur (`MAX_LEN`)\n",
        "- même embedding dim\n",
        "- mêmes hyperparams d'optimisation\n",
        "\n",
        "On compare rapidement : accuracy + ROC-AUC sur validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "cwd = Path.cwd().resolve()\n",
        "PROJECT_DIR = None\n",
        "for p in [cwd] + list(cwd.parents):\n",
        "    if (p / 'src').exists():\n",
        "        PROJECT_DIR = p\n",
        "        break\n",
        "if PROJECT_DIR is None:\n",
        "    raise RuntimeError(f\"Could not find project root containing 'src' starting from: {cwd}\")\n",
        "sys.path.insert(0, str(PROJECT_DIR))\n",
        "\n",
        "from src.text_preprocessing import TextPreprocessor\n",
        "from src.model_architecture import ModelConfig, build_bilstm_model, build_gru_model\n",
        "\n",
        "print('Project dir:', PROJECT_DIR)\n",
        "print('Python:', sys.version)\n",
        "print('TensorFlow:', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Charger IMDB (vectorisé + padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_WORDS = 10_000\n",
        "MAX_LEN = 200\n",
        "VAL_SIZE = 5_000\n",
        "\n",
        "pre = TextPreprocessor(max_words=MAX_WORDS, max_len=MAX_LEN)\n",
        "data = pre.load_imdb_text(validation_size=VAL_SIZE, seed=42)\n",
        "\n",
        "X_train, y_train = data.X_train, data.y_train\n",
        "X_val, y_val = data.X_val, data.y_val\n",
        "\n",
        "print('X_train:', X_train.shape, X_train.dtype)\n",
        "print('X_val  :', X_val.shape, X_val.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Config commune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = ModelConfig(\n",
        "    vocab_size=MAX_WORDS,\n",
        "    max_len=MAX_LEN,\n",
        "    embedding_dim=128,\n",
        "    rnn_units=64,\n",
        "    dropout=0.3,\n",
        ")\n",
        "cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train 2 epochs — BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bilstm = build_bilstm_model(cfg)\n",
        "hist_bilstm = bilstm.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=2,\n",
        "    batch_size=128,\n",
        "    verbose=1,\n",
        ")\n",
        "bilstm_metrics = bilstm.evaluate(X_val, y_val, verbose=0)\n",
        "print('BiLSTM val:', dict(zip(bilstm.metrics_names, [float(x) for x in bilstm_metrics])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Train 2 epochs — BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigru = build_gru_model(cfg)\n",
        "hist_bigru = bigru.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=2,\n",
        "    batch_size=128,\n",
        "    verbose=1,\n",
        ")\n",
        "bigru_metrics = bigru.evaluate(X_val, y_val, verbose=0)\n",
        "print('BiGRU val:', dict(zip(bigru.metrics_names, [float(x) for x in bigru_metrics])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Comparaison simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def last_val(metric_name: str, hist) -> float:\n",
        "    key = f'val_{metric_name}'\n",
        "    return float(hist.history.get(key, [np.nan])[-1])\n",
        "\n",
        "summary = {\n",
        "    'BiLSTM': {\n",
        "        'val_accuracy': last_val('accuracy', hist_bilstm),\n",
        "        'val_roc_auc': last_val('roc_auc', hist_bilstm),\n",
        "    },\n",
        "    'BiGRU': {\n",
        "        'val_accuracy': last_val('accuracy', hist_bigru),\n",
        "        'val_roc_auc': last_val('roc_auc', hist_bigru),\n",
        "    },\n",
        "}\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ Fin mini-exercice.\n",
        "\n",
        "Note : sur 2 epochs, les résultats peuvent être bruyants. L'objectif est juste de voir une différence de dynamique (vitesse d'apprentissage/stabilité)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
