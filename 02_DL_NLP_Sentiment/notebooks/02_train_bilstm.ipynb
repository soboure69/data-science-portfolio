{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# J2 — Modèle Embedding + BiLSTM (training)\n",
        "\n",
        "Objectif : construire un modèle **Embedding + BiLSTM**, entraîner, et sauvegarder le modèle entraîné.\n",
        "\n",
        "Notes :\n",
        "- On utilise `TextVectorization` (déjà vu en J1) via `TextPreprocessor`.\n",
        "- On garde un split train/val pour surveiller l'overfitting (J3 ira plus loin sur les courbes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project dir: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\n",
            "Python: 3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]\n",
            "TensorFlow: 2.13.0\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "cwd = Path.cwd().resolve()\n",
        "PROJECT_DIR = None\n",
        "for p in [cwd] + list(cwd.parents):\n",
        "    if (p / 'src').exists():\n",
        "        PROJECT_DIR = p\n",
        "        break\n",
        "if PROJECT_DIR is None:\n",
        "    raise RuntimeError(f\"Could not find project root containing 'src' starting from: {cwd}\")\n",
        "sys.path.insert(0, str(PROJECT_DIR))\n",
        "\n",
        "from src.text_preprocessing import TextPreprocessor\n",
        "from src.model_architecture import ModelConfig, build_bilstm_model\n",
        "\n",
        "print('Project dir:', PROJECT_DIR)\n",
        "print('Python:', sys.version)\n",
        "print('TensorFlow:', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Charger IMDB (vectorisé + padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (20000, 200) int64\n",
            "X_val  : (5000, 200) int64\n",
            "y_train: (20000,) int32\n",
            "Churn-like label balance (mean): 0.5001\n"
          ]
        }
      ],
      "source": [
        "MAX_WORDS = 10_000\n",
        "MAX_LEN = 200\n",
        "VAL_SIZE = 5_000\n",
        "\n",
        "pre = TextPreprocessor(max_words=MAX_WORDS, max_len=MAX_LEN)\n",
        "data = pre.load_imdb_text(validation_size=VAL_SIZE, seed=42)\n",
        "\n",
        "X_train, y_train = data.X_train, data.y_train\n",
        "X_val, y_val = data.X_val, data.y_val\n",
        "\n",
        "print('X_train:', X_train.shape, X_train.dtype)\n",
        "print('X_val  :', X_val.shape, X_val.dtype)\n",
        "print('y_train:', y_train.shape, y_train.dtype)\n",
        "print('Churn-like label balance (mean):', float(y_train.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Construire le modèle (Embedding + BiLSTM + Dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 128)          1280000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 200, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1378945 (5.26 MB)\n",
            "Trainable params: 1378945 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cfg = ModelConfig(\n",
        "    vocab_size=MAX_WORDS,\n",
        "    max_len=MAX_LEN,\n",
        "    embedding_dim=128,\n",
        "    rnn_units=64,\n",
        "    dropout=0.3,\n",
        ")\n",
        "model = build_bilstm_model(cfg)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Training (EarlyStopping + Checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "157/157 [==============================] - 130s 830ms/step - loss: 0.1751 - accuracy: 0.9385 - roc_auc: 0.9796 - val_loss: 0.3393 - val_accuracy: 0.8568 - val_roc_auc: 0.9314\n",
            "Epoch 2/6\n",
            "157/157 [==============================] - 263s 2s/step - loss: 0.1448 - accuracy: 0.9508 - roc_auc: 0.9857 - val_loss: 0.3869 - val_accuracy: 0.8718 - val_roc_auc: 0.9343\n",
            "Epoch 3/6\n",
            "157/157 [==============================] - 136s 867ms/step - loss: 0.1396 - accuracy: 0.9508 - roc_auc: 0.9869 - val_loss: 0.4100 - val_accuracy: 0.8666 - val_roc_auc: 0.9312\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The following argument(s) are not supported with the native Keras format: ['include_optimizer']",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_ckpt_path.exists():\n\u001b[32m     32\u001b[39m     model.load_weights(\u001b[38;5;28mstr\u001b[39m(weights_ckpt_path))\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_model_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mBest weights saved to:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(weights_ckpt_path))\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mFinal model saved to:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(final_model_path))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bello\\Documents\\data-science-portfolio\\.venv_dl\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bello\\Documents\\data-science-portfolio\\.venv_dl\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:142\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(model, filepath, overwrite, save_format, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    143\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe following argument(s) are not supported \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    144\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    145\u001b[39m         )\n\u001b[32m    146\u001b[39m     saving_lib.save_model(model, filepath)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# Legacy case\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: The following argument(s) are not supported with the native Keras format: ['include_optimizer']"
          ]
        }
      ],
      "source": [
        "MODELS_DIR = PROJECT_DIR / 'models'\n",
        "RESULTS_DIR = PROJECT_DIR / 'results'\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Workaround for Keras format compatibility: checkpoint weights during training,\n",
        "# then save the full model at the end.\n",
        "weights_ckpt_path = MODELS_DIR / 'sentiment_model.weights.h5'\n",
        "final_model_path = MODELS_DIR / 'sentiment_model.keras'\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=str(weights_ckpt_path),\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    ),\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=6,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Ensure best weights are on the model (restore_best_weights=True should already do it)\n",
        "if weights_ckpt_path.exists():\n",
        "    model.load_weights(str(weights_ckpt_path))\n",
        "\n",
        "model.save(str(final_model_path))\n",
        "\n",
        "print('Best weights saved to:', str(weights_ckpt_path))\n",
        "print('Final model saved to:', str(final_model_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Évaluation rapide (val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.3402\n",
            "accuracy: 0.8618\n",
            "roc_auc: 0.9382\n"
          ]
        }
      ],
      "source": [
        "val_metrics = model.evaluate(X_val, y_val, verbose=0)\n",
        "for name, value in zip(model.metrics_names, val_metrics):\n",
        "    print(f'{name}: {value:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Sanity check : prédire une phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob(positive): 0.822 => Positive\n"
          ]
        }
      ],
      "source": [
        "sample = 'This movie was surprisingly good, I loved the acting and the story.'\n",
        "x = data.vectorizer(tf.constant([sample])).numpy()\n",
        "p = float(model.predict(x, verbose=0)[0][0])\n",
        "label = 'Positive' if p >= 0.5 else 'Negative'\n",
        "print('Prob(positive):', round(p, 3), '=>', label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ Fin de J2 : modèle BiLSTM entraîné + sauvegardé en `models/sentiment_model.keras`.\n",
        "\n",
        "Prochain : mini-exercice *Ablation* (LSTM vs GRU, 2 epochs) puis J3 (courbes + évaluation test)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
