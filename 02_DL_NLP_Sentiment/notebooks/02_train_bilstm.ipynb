{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# J2 — Modèle Embedding + BiLSTM (training)\n",
        "\n",
        "Objectif : construire un modèle **Embedding + BiLSTM**, entraîner, et sauvegarder le modèle entraîné.\n",
        "\n",
        "Notes :\n",
        "- On utilise `TextVectorization` (déjà vu en J1) via `TextPreprocessor`.\n",
        "- On garde un split train/val pour surveiller l'overfitting (J3 ira plus loin sur les courbes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project dir: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\n",
            "Python: 3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]\n",
            "TensorFlow: 2.13.0\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "cwd = Path.cwd().resolve()\n",
        "PROJECT_DIR = None\n",
        "for p in [cwd] + list(cwd.parents):\n",
        "    if (p / 'src').exists():\n",
        "        PROJECT_DIR = p\n",
        "        break\n",
        "if PROJECT_DIR is None:\n",
        "    raise RuntimeError(f\"Could not find project root containing 'src' starting from: {cwd}\")\n",
        "sys.path.insert(0, str(PROJECT_DIR))\n",
        "\n",
        "from src.text_preprocessing import TextPreprocessor\n",
        "from src.model_architecture import ModelConfig, build_bilstm_model\n",
        "\n",
        "print('Project dir:', PROJECT_DIR)\n",
        "print('Python:', sys.version)\n",
        "print('TensorFlow:', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Charger IMDB (vectorisé + padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (20000, 200) int64\n",
            "X_val  : (5000, 200) int64\n",
            "y_train: (20000,) int32\n",
            "Churn-like label balance (mean): 0.5001\n"
          ]
        }
      ],
      "source": [
        "MAX_WORDS = 10_000\n",
        "MAX_LEN = 200\n",
        "VAL_SIZE = 5_000\n",
        "\n",
        "pre = TextPreprocessor(max_words=MAX_WORDS, max_len=MAX_LEN)\n",
        "data = pre.load_imdb_text(validation_size=VAL_SIZE, seed=42)\n",
        "\n",
        "X_train, y_train = data.X_train, data.y_train\n",
        "X_val, y_val = data.X_val, data.y_val\n",
        "\n",
        "print('X_train:', X_train.shape, X_train.dtype)\n",
        "print('X_val  :', X_val.shape, X_val.dtype)\n",
        "print('y_train:', y_train.shape, y_train.dtype)\n",
        "print('Churn-like label balance (mean):', float(y_train.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Construire le modèle (Embedding + BiLSTM + Dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 128)          1280000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 200, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1378945 (5.26 MB)\n",
            "Trainable params: 1378945 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cfg = ModelConfig(\n",
        "    vocab_size=MAX_WORDS,\n",
        "    max_len=MAX_LEN,\n",
        "    embedding_dim=128,\n",
        "    rnn_units=64,\n",
        "    dropout=0.3,\n",
        ")\n",
        "model = build_bilstm_model(cfg)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Training (EarlyStopping + Checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "157/157 [==============================] - 145s 925ms/step - loss: 0.2835 - accuracy: 0.8903 - roc_auc: 0.9499 - val_loss: 0.3402 - val_accuracy: 0.8618 - val_roc_auc: 0.9382\n",
            "Epoch 2/6\n",
            "157/157 [==============================] - 164s 1s/step - loss: 0.2162 - accuracy: 0.9194 - roc_auc: 0.9703 - val_loss: 0.3452 - val_accuracy: 0.8762 - val_roc_auc: 0.9396\n",
            "Epoch 3/6\n",
            "157/157 [==============================] - 469s 3s/step - loss: 0.1722 - accuracy: 0.9401 - roc_auc: 0.9801 - val_loss: 0.3430 - val_accuracy: 0.8682 - val_roc_auc: 0.9367\n",
            "Best weights saved to: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\\models\\sentiment_model.weights.h5\n",
            "Final model saved to: C:\\Users\\bello\\Documents\\data-science-portfolio\\02_DL_NLP_Sentiment\\models\\sentiment_model.keras\n"
          ]
        }
      ],
      "source": [
        "MODELS_DIR = PROJECT_DIR / 'models'\n",
        "RESULTS_DIR = PROJECT_DIR / 'results'\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Workaround for Keras format compatibility: checkpoint weights during training,\n",
        "# then save the full model at the end.\n",
        "weights_ckpt_path = MODELS_DIR / 'sentiment_model.weights.h5'\n",
        "final_model_path = MODELS_DIR / 'sentiment_model.keras'\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=str(weights_ckpt_path),\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    ),\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=6,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Ensure best weights are on the model (restore_best_weights=True should already do it)\n",
        "if weights_ckpt_path.exists():\n",
        "    model.load_weights(str(weights_ckpt_path))\n",
        "\n",
        "model.save(str(final_model_path))\n",
        "\n",
        "print('Best weights saved to:', str(weights_ckpt_path))\n",
        "print('Final model saved to:', str(final_model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Évaluation rapide (val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.3402\n",
            "accuracy: 0.8618\n",
            "roc_auc: 0.9382\n"
          ]
        }
      ],
      "source": [
        "val_metrics = model.evaluate(X_val, y_val, verbose=0)\n",
        "for name, value in zip(model.metrics_names, val_metrics):\n",
        "    print(f'{name}: {value:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Sanity check : prédire une phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob(positive): 0.822 => Positive\n"
          ]
        }
      ],
      "source": [
        "sample = 'This movie was surprisingly good, I loved the acting and the story.'\n",
        "x = data.vectorizer(tf.constant([sample])).numpy()\n",
        "p = float(model.predict(x, verbose=0)[0][0])\n",
        "label = 'Positive' if p >= 0.5 else 'Negative'\n",
        "print('Prob(positive):', round(p, 3), '=>', label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ Fin de J2 : modèle BiLSTM entraîné + sauvegardé en `models/sentiment_model.keras`.\n",
        "\n",
        "Prochain : mini-exercice *Ablation* (LSTM vs GRU, 2 epochs) puis J3 (courbes + évaluation test)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
